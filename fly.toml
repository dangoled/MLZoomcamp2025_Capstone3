# fly.toml
# Carbon Footprint Prediction API
# Configuration for Fly.io deployment

app = "carbon-footprint-predictor"


[build]
  dockerfile = "Dockerfile"

[deploy]
  release_command = "python migrate.py"  # Optional: run migrations on deploy
  strategy = "rolling"  # Zero-downtime deployments

[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0
  
  [[http_service.checks]]
    grace_period = "1s"
    interval = "15s"
    method = "GET"
    path = "/health"
    timeout = "2s"
    tls_skip_verify = false

    [http_service.checks.headers]
      Content-Type = "application/json"

  [[http_service.checks]]
    grace_period = "5s"
    interval = "30s"
    method = "GET"
    path = "/docs"
    timeout = "5s"

[mounts]
  source = "carbon_footprint_data"
  destination = "/app/data"

[vm]
  cpu_kind = "shared"
  cpus = 2
  memory_mb = 1024
  gpu_kind = "none"  # Set to "a100-pcie-40gb" if you need GPU for training

[env]
  # Environment Variables
  ENVIRONMENT = "production"
  LOG_LEVEL = "INFO"
  MODEL_PATH = "/app/models/carbon_footprint_model.pkl"
  DATA_PATH = "/app/data/personal_carbon_footprint_behavior.csv"
  
  # FastAPI Settings
  HOST = "0.0.0.0"
  PORT = "8000"
  RELOAD = "false"
  WORKERS = "2"
  
  # Security
  SECRET_KEY = "change-this-in-production-with-fly-secrets-set"
  API_KEY = "generate-a-secure-api-key"
  
  
  
  # Secrets (run: fly secrets set SECRET_KEY=your-secret-key)
# These will be encrypted and not visible in this file
# [secrets]
#   SECRET_KEY = ""
#   DATABASE_PASSWORD = ""
#   API_KEY = ""

# Optional: Multiple process types for different services
# [[services]]
#   internal_port = 8001
#   protocol = "tcp"
#   processes = ["training"]

# [[services]]
#   internal_port = 8002
#   protocol = "tcp"
#   processes = ["monitoring"]

# Scale configuration for different environments
[scale]
  min = 1
  max = 3
  target_cpu_percent = 70
  target_memory_percent = 80

# Health checks (extended)
[checks]
  [checks.app_health]
    port = 8000
    type = "http"
    interval = "30s"
    timeout = "5s"
    grace_period = "10s"
    path = "/health"
    method = "GET"
    [checks.app_health.headers]
      X-Health-Check = "true"
  
  [checks.model_health]
    port = 8000
    type = "http"
    interval = "60s"
    timeout = "10s"
    grace_period = "30s"
    path = "/api/v1/model/health"
    method = "GET"

# Metrics (if you add Prometheus later)
[metrics]
  port = 9090
  path = "/metrics"

# Optional: Auto-scaling rules
[[autoscaling]]
  metric = "cpu"
  target = 70
  min_count = 1
  max_count = 3

[[autoscaling]]
  metric = "memory"
  target = 80
  min_count = 1
  max_count = 3

# Optional: Scheduled tasks (crons)
# [[vm]]
#   schedule = "0 */6 * * *"  # Every 6 hours
#   command = "python retrain_model.py"

# Process groups for different application components
# [processes]
#   app = "uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2"
#   worker = "python worker.py"
#   scheduler = "python scheduler.py"